{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmm84766/Question-Answering/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWUYBRMEfY5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import urllib\n",
        "import sys\n",
        "import os\n",
        "import zipfile\n",
        "import tarfile\n",
        "import json \n",
        "import hashlib\n",
        "import re\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKYkmdFAiBkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_zip_file = \"glove.6B.zip\"\n",
        "glove_vectors_file = \"glove.6B.50d.txt\"\n",
        "\n",
        "# 15 MB\n",
        "data_set_zip = \"tasks_1-20_v1-2.tar.gz\"\n",
        "\n",
        "#Select \"task 5\"\n",
        "train_set_file = \"qa5_three-arg-relations_train.txt\"\n",
        "test_set_file = \"qa5_three-arg-relations_test.txt\"\n",
        "\n",
        "train_set_post_file = \"tasks_1-20_v1-2/en/\"+train_set_file\n",
        "test_set_post_file = \"tasks_1-20_v1-2/en/\"+test_set_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDHzMZEXgz4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: from urllib.request import urlretrieve, urlopen\n",
        "except ImportError: \n",
        "    from urllib import urlretrieve\n",
        "    from urllib2 import urlopen\n",
        "#large file - 862 MB\n",
        "if (not os.path.isfile(glove_zip_file) and\n",
        "    not os.path.isfile(glove_vectors_file)):\n",
        "    urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
        "                 glove_zip_file)\n",
        "if (not os.path.isfile(data_set_zip) and\n",
        "    not (os.path.isfile(train_set_file) and os.path.isfile(test_set_file))):\n",
        "    urlretrieve (\"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\", \n",
        "                 data_set_zip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6RC1Ejbhtyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unzip_single_file(zip_file_name, output_file_name):\n",
        "    \"\"\"\n",
        "        If the output file is already created, don't recreate\n",
        "        If the output file does not exist, create it from the zipFile\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(output_file_name):\n",
        "        with open(output_file_name, 'wb') as out_file:\n",
        "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
        "                for info in zipped.infolist():\n",
        "                    if output_file_name in info.filename:\n",
        "                        with zipped.open(info) as requested_file:\n",
        "                            out_file.write(requested_file.read())\n",
        "                            return\n",
        "def targz_unzip_single_file(zip_file_name, output_file_name, interior_relative_path):\n",
        "    if not os.path.isfile(output_file_name):\n",
        "        with tarfile.open(zip_file_name) as un_zipped:\n",
        "            un_zipped.extract(interior_relative_path+output_file_name)    \n",
        "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
        "targz_unzip_single_file(data_set_zip, train_set_file, \"tasks_1-20_v1-2/en/\")\n",
        "targz_unzip_single_file(data_set_zip, test_set_file, \"tasks_1-20_v1-2/en/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mbTFHRCj8jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_wordmap = {}\n",
        "with open(glove_vectors_file, \"r\", encoding=\"utf8\") as glove:\n",
        "    for line in glove:\n",
        "        name, vector = tuple(line.split(\" \", 1))\n",
        "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ1K952GkPBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wvecs = []\n",
        "for item in glove_wordmap.items():\n",
        "    wvecs.append(item[1])\n",
        "s = np.vstack(wvecs)\n",
        "\n",
        "# Gather the distribution hyperparameters\n",
        "v = np.var(s,0) \n",
        "m = np.mean(s,0) \n",
        "RS = np.random.RandomState()\n",
        "\n",
        "def fill_unk(unk):\n",
        "    global glove_wordmap\n",
        "    glove_wordmap[unk] = RS.multivariate_normal(m,np.diag(v))\n",
        "    return glove_wordmap[unk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5rD0AYQkVVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence2sequence(sentence):\n",
        "    \"\"\"\n",
        "\n",
        "    - Turns an input paragraph into an (m,d) matrix, \n",
        "        where n is the number of tokens in the sentence\n",
        "        and d is the number of dimensions each word vector has.\n",
        "\n",
        "      TensorFlow doesn't need to be used here, as simply\n",
        "      turning the sentence into a sequence based off our \n",
        "      mapping does not need the computational power that\n",
        "      TensorFlow provides. Normal Python suffices for this task.\n",
        "    \"\"\"\n",
        "    tokens = sentence.strip('\"(),-').lower().split(\" \")\n",
        "    rows = []\n",
        "    words = []\n",
        "    #Greedy search for tokens\n",
        "    for token in tokens:\n",
        "        i = len(token)\n",
        "        while len(token) > 0:\n",
        "            word = token[:i]\n",
        "            if word in glove_wordmap:\n",
        "                rows.append(glove_wordmap[word])\n",
        "                words.append(word)\n",
        "                token = token[i:]\n",
        "                i = len(token)\n",
        "                continue\n",
        "            else:\n",
        "                i = i-1\n",
        "            if i == 0:\n",
        "                # word OOV\n",
        "                # https://arxiv.org/pdf/1611.01436.pdf\n",
        "                rows.append(fill_unk(token))\n",
        "                words.append(token)\n",
        "                break\n",
        "    return np.array(rows), words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQCYnF6Skb1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence2sequence(sentence):\n",
        "    \"\"\"\n",
        "\n",
        "    - Turns an input paragraph into an (m,d) matrix, \n",
        "        where n is the number of tokens in the sentence\n",
        "        and d is the number of dimensions each word vector has.\n",
        "\n",
        "      TensorFlow doesn't need to be used here, as simply\n",
        "      turning the sentence into a sequence based off our \n",
        "      mapping does not need the computational power that\n",
        "      TensorFlow provides. Normal Python suffices for this task.\n",
        "    \"\"\"\n",
        "    tokens = sentence.strip('\"(),-').lower().split(\" \")\n",
        "    rows = []\n",
        "    words = []\n",
        "    #Greedy search for tokens\n",
        "    for token in tokens:\n",
        "        i = len(token)\n",
        "        while len(token) > 0:\n",
        "            word = token[:i]\n",
        "            if word in glove_wordmap:\n",
        "                rows.append(glove_wordmap[word])\n",
        "                words.append(word)\n",
        "                token = token[i:]\n",
        "                i = len(token)\n",
        "                continue\n",
        "            else:\n",
        "                i = i-1\n",
        "            if i == 0:\n",
        "                # word OOV\n",
        "                # https://arxiv.org/pdf/1611.01436.pdf\n",
        "                rows.append(fill_unk(token))\n",
        "                words.append(token)\n",
        "                break\n",
        "    return np.array(rows), words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbeThTe8km46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def contextualize(set_file):\n",
        "    \"\"\"\n",
        "    Read in the dataset of questions and build question+answer -> context sets.\n",
        "    Output is a list of data points, each of which is a 7-element tuple containing:\n",
        "        The sentences in the context in vectorized form.\n",
        "        The sentences in the context as a list of string tokens.\n",
        "        The question in vectorized form.\n",
        "        The question as a list of string tokens.\n",
        "        The answer in vectorized form.\n",
        "        The answer as a list of string tokens.\n",
        "        A list of numbers for supporting statements, which is currently unused.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    context = []\n",
        "    with open(set_file, \"r\", encoding=\"utf8\") as train:\n",
        "        for line in train:\n",
        "            l, ine = tuple(line.split(\" \", 1))\n",
        "            # Split the line numbers from the sentences they refer to.\n",
        "            if l is \"1\":\n",
        "                # New contexts always start with 1, \n",
        "                # so this is a signal to reset the context.\n",
        "                context = []\n",
        "            if \"\\t\" in ine: \n",
        "                # Tabs are the separator between questions and answers,\n",
        "                # and are not present in context statements.\n",
        "                question, answer, support = tuple(ine.split(\"\\t\"))\n",
        "                data.append((tuple(zip(*context))+\n",
        "                             sentence2sequence(question)+\n",
        "                             sentence2sequence(answer)+\n",
        "                             ([int(s) for s in support.split()],)))\n",
        "                # Multiple questions may refer to the same context, so we don't reset it.\n",
        "            else:\n",
        "                # Context sentence.\n",
        "                context.append(sentence2sequence(ine[:-1]))\n",
        "    return data\n",
        "train_data = contextualize(train_set_post_file)\n",
        "test_data = contextualize(test_set_post_file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdkYncJ5BcED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_train_data = []\n",
        "def finalize(data):\n",
        "    \"\"\"\n",
        "    Prepares data generated by contextualize() for use in the network.\n",
        "    \"\"\"\n",
        "    final_data = []\n",
        "    for cqas in train_data:\n",
        "        contextvs, contextws, qvs, qws, avs, aws, spt = cqas\n",
        "\n",
        "        lengths = itertools.accumulate(len(cvec) for cvec in contextvs)\n",
        "        context_vec = np.concatenate(contextvs)\n",
        "        context_words = sum(contextws,[])\n",
        "\n",
        "        # Location markers for the beginnings of new sentences.\n",
        "        sentence_ends = np.array(list(lengths)) \n",
        "        final_data.append((context_vec, sentence_ends, qvs, spt, context_words, cqas, avs, aws))\n",
        "    return np.array(final_data)\n",
        "final_train_data = finalize(train_data)   \n",
        "final_test_data = finalize(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUv-ZjIgBg5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riZatMo3Blwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "# The number of dimensions used to store data passed between recurrent layers in the network.\n",
        "recurrent_cell_size = 128\n",
        "\n",
        "# The number of dimensions in our word vectorizations.\n",
        "D = 50 \n",
        "\n",
        "# How quickly the network learns. Too high, and we may run into numeric instability \n",
        "# or other issues.\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Dropout probabilities. For a description of dropout and what these probabilities are, \n",
        "# see Entailment with TensorFlow.\n",
        "input_p, output_p = 0.5, 0.5\n",
        "\n",
        "# How many questions we train on at a time.\n",
        "batch_size = 128\n",
        "\n",
        "# Number of passes in episodic memory. We'll get to this later.\n",
        "passes = 4\n",
        "\n",
        "# Feed Forward layer sizes: the number of dimensions used to store data passed from feed-forward layers.\n",
        "ff_hidden_size = 256\n",
        "\n",
        "weight_decay = 0.00000001\n",
        "# The strength of our regularization. Increase to encourage sparsity in episodic memory, \n",
        "# but makes training slower. Don't make this larger than leraning_rate.\n",
        "\n",
        "training_iterations_count = 400000\n",
        "# How many questions the network trains on each time it is trained. \n",
        "# Some questions are counted multiple times.\n",
        "\n",
        "display_step = 100\n",
        "# How many iterations of training occur before each validation check.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcWKpFEgBtfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "17e9ee67-3472-4b5e-aa61-44af9582e6cc"
      },
      "source": [
        "# Input Module\n",
        "\n",
        "# Context: A [batch_size, maximum_context_length, word_vectorization_dimensions] tensor \n",
        "# that contains all the context information.\n",
        "context = tf.placeholder(tf.float32, [None, None, D], \"context\")  \n",
        "context_placeholder = context # I use context as a variable name later on\n",
        "\n",
        "# input_sentence_endings: A [batch_size, maximum_sentence_count, 2] tensor that \n",
        "# contains the locations of the ends of sentences. \n",
        "input_sentence_endings = tf.placeholder(tf.int32, [None, None, 2], \"sentence\")\n",
        "\n",
        "# recurrent_cell_size: the number of hidden units in recurrent layers.\n",
        "input_gru = tf.contrib.rnn.GRUCell(recurrent_cell_size)\n",
        "\n",
        "# input_p: The probability of maintaining a specific hidden input unit.\n",
        "# Likewise, output_p is the probability of maintaining a specific hidden output unit.\n",
        "gru_drop = tf.contrib.rnn.DropoutWrapper(input_gru, input_p, output_p)\n",
        "\n",
        "# dynamic_rnn also returns the final internal state. We don't need that, and can\n",
        "# ignore the corresponding output (_). \n",
        "input_module_outputs, _ = tf.nn.dynamic_rnn(gru_drop, context, dtype=tf.float32, scope = \"input_module\")\n",
        "\n",
        "# cs: the facts gathered from the context.\n",
        "cs = tf.gather_nd(input_module_outputs, input_sentence_endings)\n",
        "# to use every word as a fact, useful for tasks with one-sentence contexts\n",
        "s = input_module_outputs\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-14-6ad0c250cfe3>:9: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-14-6ad0c250cfe3>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHdGvPooB5lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question Module\n",
        "\n",
        "# query: A [batch_size, maximum_question_length, word_vectorization_dimensions] tensor \n",
        "#  that contains all of the questions.\n",
        "\n",
        "query = tf.placeholder(tf.float32, [None, None, D], \"query\")\n",
        "\n",
        "# input_query_lengths: A [batch_size, 2] tensor that contains question length information. \n",
        "# input_query_lengths[:,1] has the actual lengths; input_query_lengths[:,0] is a simple range() \n",
        "# so that it plays nice with gather_nd.\n",
        "input_query_lengths = tf.placeholder(tf.int32, [None, 2], \"query_lengths\")\n",
        "\n",
        "question_module_outputs, _ = tf.nn.dynamic_rnn(gru_drop, query, dtype=tf.float32, \n",
        "                                               scope = tf.VariableScope(True, \"input_module\"))\n",
        "\n",
        "# q: the question states. A [batch_size, recurrent_cell_size] tensor.\n",
        "q = tf.gather_nd(question_module_outputs, input_query_lengths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYJqdfdKCBw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "3ab333d4-a3a0-4cbb-dc2b-23f6a13f9f75"
      },
      "source": [
        "# Episodic Memory\n",
        "\n",
        "# make sure the current memory (i.e. the question vector) is broadcasted along the facts dimension\n",
        "size = tf.stack([tf.constant(1),tf.shape(cs)[1], tf.constant(1)])\n",
        "re_q = tf.tile(tf.reshape(q,[-1,1,recurrent_cell_size]),size)\n",
        "\n",
        "\n",
        "# Final output for attention, needs to be 1 in order to create a mask\n",
        "output_size = 1 \n",
        "\n",
        "# Weights and biases\n",
        "attend_init = tf.random_normal_initializer(stddev=0.1)\n",
        "w_1 = tf.get_variable(\"attend_w1\", [1,recurrent_cell_size*7, recurrent_cell_size], \n",
        "                      tf.float32, initializer = attend_init)\n",
        "w_2 = tf.get_variable(\"attend_w2\", [1,recurrent_cell_size, output_size], \n",
        "                      tf.float32, initializer = attend_init)\n",
        "\n",
        "b_1 = tf.get_variable(\"attend_b1\", [1, recurrent_cell_size], \n",
        "                      tf.float32, initializer = attend_init)\n",
        "b_2 = tf.get_variable(\"attend_b2\", [1, output_size], \n",
        "                      tf.float32, initializer = attend_init)\n",
        "\n",
        "# Regulate all the weights and biases\n",
        "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(w_1))\n",
        "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(b_1))\n",
        "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(w_2))\n",
        "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(b_2))\n",
        "\n",
        "def attention(c, mem, existing_facts):\n",
        "    \"\"\"\n",
        "    Custom attention mechanism.\n",
        "    c: A [batch_size, maximum_sentence_count, recurrent_cell_size] tensor \n",
        "        that contains all the facts from the contexts.\n",
        "    mem: A [batch_size, maximum_sentence_count, recurrent_cell_size] tensor that \n",
        "        contains the current memory. It should be the same memory for all facts for accurate results.\n",
        "    existing_facts: A [batch_size, maximum_sentence_count, 1] tensor that \n",
        "        acts as a binary mask for which facts exist and which do not.\n",
        "\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(\"attending\") as scope:\n",
        "        # attending: The metrics by which we decide what to attend to.\n",
        "        attending = tf.concat([c, mem, re_q, c * re_q,  c * mem, (c-re_q)**2, (c-mem)**2], 2)\n",
        "\n",
        "        # m1: First layer of multiplied weights for the feed-forward network. \n",
        "        #     We tile the weights in order to manually broadcast, since tf.matmul does not\n",
        "        #     automatically broadcast batch matrix multiplication as of TensorFlow 1.2.\n",
        "        m1 = tf.matmul(attending * existing_facts, \n",
        "                       tf.tile(w_1, tf.stack([tf.shape(attending)[0],1,1]))) * existing_facts\n",
        "        # bias_1: A masked version of the first feed-forward layer's bias\n",
        "        #     over only existing facts.\n",
        "\n",
        "        bias_1 = b_1 * existing_facts\n",
        "\n",
        "        # tnhan: First nonlinearity. In the original paper, this is a tanh nonlinearity; \n",
        "        #        choosing relu was a design choice intended to avoid issues with \n",
        "        #        low gradient magnitude when the tanh returned values close to 1 or -1. \n",
        "        tnhan = tf.nn.relu(m1 + bias_1)\n",
        "\n",
        "        # m2: Second layer of multiplied weights for the feed-forward network. \n",
        "        #     Still tiling weights for the same reason described in m1's comments.\n",
        "        m2 = tf.matmul(tnhan, tf.tile(w_2, tf.stack([tf.shape(attending)[0],1,1])))\n",
        "\n",
        "        # bias_2: A masked version of the second feed-forward layer's bias.\n",
        "        bias_2 = b_2 * existing_facts\n",
        "\n",
        "        # norm_m2: A normalized version of the second layer of weights, which is used \n",
        "        #     to help make sure the softmax nonlinearity doesn't saturate.\n",
        "        norm_m2 = tf.nn.l2_normalize(m2 + bias_2, -1)\n",
        "\n",
        "        # softmaxable: A hack in order to use sparse_softmax on an otherwise dense tensor. \n",
        "        #     We make norm_m2 a sparse tensor, then make it dense again after the operation.\n",
        "        softmax_idx = tf.where(tf.not_equal(norm_m2, 0))[:,:-1]\n",
        "        softmax_gather = tf.gather_nd(norm_m2[...,0], softmax_idx)\n",
        "        softmax_shape = tf.shape(norm_m2, out_type=tf.int64)[:-1]\n",
        "        softmaxable = tf.SparseTensor(softmax_idx, softmax_gather, softmax_shape)\n",
        "        return tf.expand_dims(tf.sparse_tensor_to_dense(tf.sparse_softmax(softmaxable)),-1)\n",
        "\n",
        "# facts_0s: a [batch_size, max_facts_length, 1] tensor \n",
        "#     whose values are 1 if the corresponding fact exists and 0 if not.\n",
        "facts_0s = tf.cast(tf.count_nonzero(input_sentence_endings[:,:,-1:],-1,keep_dims=True),tf.float32)\n",
        "\n",
        "\n",
        "with tf.variable_scope(\"Episodes\") as scope:\n",
        "    attention_gru = tf.contrib.rnn.GRUCell(recurrent_cell_size)\n",
        "\n",
        "    # memory: A list of all tensors that are the (current or past) memory state \n",
        "    #   of the attention mechanism.\n",
        "    memory = [q]\n",
        "\n",
        "    # attends: A list of all tensors that represent what the network attends to.\n",
        "    attends = []\n",
        "    for a in range(passes):\n",
        "        # attention mask\n",
        "        attend_to = attention(cs, tf.tile(tf.reshape(memory[-1],[-1,1,recurrent_cell_size]),size),\n",
        "                              facts_0s)\n",
        "\n",
        "        # Inverse attention mask, for what's retained in the state.\n",
        "        retain = 1-attend_to\n",
        "\n",
        "        # GRU pass over the facts, according to the attention mask.\n",
        "        while_valid_index = (lambda state, index: index < tf.shape(cs)[1])\n",
        "        update_state = (lambda state, index: (attend_to[:,index,:] * \n",
        "                                                 attention_gru(cs[:,index,:], state)[0] + \n",
        "                                                 retain[:,index,:] * state))\n",
        "        # start loop with most recent memory and at the first index\n",
        "        memory.append(tuple(tf.while_loop(while_valid_index,\n",
        "                          (lambda state, index: (update_state(state,index),index+1)),\n",
        "                           loop_vars = [memory[-1], 0]))[0]) \n",
        "\n",
        "        attends.append(attend_to)\n",
        "\n",
        "        # Reuse variables so the GRU pass uses the same variables every pass.\n",
        "        scope.reuse_variables()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-8d9c84da2a3c>:77: calling count_nonzero (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "reduction_indices is deprecated, use axis instead\n",
            "WARNING:tensorflow:From <ipython-input-16-8d9c84da2a3c>:69: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxywlUlUCWwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Answer Module\n",
        "\n",
        "# a0: Final memory state. (Input to answer module)\n",
        "a0 = tf.concat([memory[-1], q], -1)\n",
        "\n",
        "# fc_init: Initializer for the final fully connected layer's weights.\n",
        "fc_init = tf.random_normal_initializer(stddev=0.1) \n",
        "\n",
        "with tf.variable_scope(\"answer\"):\n",
        "    # w_answer: The final fully connected layer's weights.\n",
        "    w_answer = tf.get_variable(\"weight\", [recurrent_cell_size*2, D], \n",
        "                               tf.float32, initializer = fc_init)\n",
        "    # Regulate the fully connected layer's weights\n",
        "    tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
        "                     tf.nn.l2_loss(w_answer)) \n",
        "\n",
        "    # The regressed word. This isn't an actual word yet; \n",
        "    #    we still have to find the closest match.\n",
        "    logit = tf.expand_dims(tf.matmul(a0, w_answer),1)\n",
        "\n",
        "    # Make a mask over which words exist.\n",
        "    with tf.variable_scope(\"ending\"):\n",
        "        all_ends = tf.reshape(input_sentence_endings, [-1,2])\n",
        "        range_ends = tf.range(tf.shape(all_ends)[0])\n",
        "        ends_indices = tf.stack([all_ends[:,0],range_ends], axis=1)\n",
        "        ind = tf.reduce_max(tf.scatter_nd(ends_indices, all_ends[:,1],\n",
        "                                          [tf.shape(q)[0], tf.shape(all_ends)[0]]),\n",
        "                            axis=-1)\n",
        "        range_ind = tf.range(tf.shape(ind)[0])\n",
        "        mask_ends = tf.cast(tf.scatter_nd(tf.stack([ind, range_ind], axis=1), \n",
        "                                          tf.ones_like(range_ind), [tf.reduce_max(ind)+1, \n",
        "                                                                    tf.shape(ind)[0]]), bool)\n",
        "        # A bit of a trick. With the locations of the ends of the mask (the last periods in \n",
        "        #  each of the contexts) as 1 and the rest as 0, we can scan with exclusive or \n",
        "        #  (starting from all 1). For each context in the batch, this will result in 1s \n",
        "        #  up until the marker (the location of that last period) and 0s afterwards.\n",
        "        mask = tf.scan(tf.logical_xor,mask_ends, tf.ones_like(range_ind, dtype=bool))\n",
        "\n",
        "    # We score each possible word inversely with their Euclidean distance to the regressed word.\n",
        "    #  The highest score (lowest distance) will correspond to the selected word.\n",
        "    logits = -tf.reduce_sum(tf.square(context*tf.transpose(tf.expand_dims(\n",
        "                    tf.cast(mask, tf.float32),-1),[1,0,2]) - logit), axis=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwyNttlfCgBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "28b8f4ef-08ee-4ab9-8e0b-84cdd43a377c"
      },
      "source": [
        "# Training\n",
        "\n",
        "# gold_standard: The real answers.\n",
        "gold_standard = tf.placeholder(tf.float32, [None, 1, D], \"answer\")\n",
        "with tf.variable_scope('accuracy'):\n",
        "    eq = tf.equal(context, gold_standard)\n",
        "    corrbool = tf.reduce_all(eq,-1)\n",
        "    logloc = tf.reduce_max(logits, -1, keep_dims = True)\n",
        "    # locs: A boolean tensor that indicates where the score \n",
        "    #  matches the minimum score. This happens on multiple dimensions, \n",
        "    #  so in the off chance there's one or two indexes that match \n",
        "    #  we make sure it matches in all indexes.\n",
        "    locs = tf.equal(logits, logloc)\n",
        "\n",
        "    # correctsbool: A boolean tensor that indicates for which \n",
        "    #   words in the context the score always matches the minimum score.\n",
        "    correctsbool = tf.reduce_any(tf.logical_and(locs, corrbool), -1)\n",
        "    # corrects: A tensor that is simply correctsbool cast to floats.\n",
        "    corrects = tf.where(correctsbool, tf.ones_like(correctsbool, dtype=tf.float32), \n",
        "                        tf.zeros_like(correctsbool,dtype=tf.float32))\n",
        "\n",
        "    # corr: corrects, but for the right answer instead of our selected answer.\n",
        "    corr = tf.where(corrbool, tf.ones_like(corrbool, dtype=tf.float32), \n",
        "                        tf.zeros_like(corrbool,dtype=tf.float32))\n",
        "with tf.variable_scope(\"loss\"):\n",
        "    # Use sigmoid cross entropy as the base loss, \n",
        "    #  with our distances as the relative probabilities. There are\n",
        "    #  multiple correct labels, for each location of the answer word within the context.\n",
        "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits = tf.nn.l2_normalize(logits,-1),\n",
        "                                                   labels = corr)\n",
        "\n",
        "    # Add regularization losses, weighted by weight_decay.\n",
        "    total_loss = tf.reduce_mean(loss) + weight_decay * tf.add_n(\n",
        "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
        "\n",
        "# TensorFlow's default implementation of the Adam optimizer works. We can adjust more than \n",
        "#  just the learning rate, but it's not necessary to find a very good optimum.\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "# Once we have an optimizer, we ask it to minimize the loss \n",
        "#   in order to work towards the proper training.\n",
        "opt_op = optimizer.minimize(total_loss)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-2e678c7d6d9c>:5: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpRAkaGXCo63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the TensorFlow session\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R2zHsanCtPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c5227d39-6919-4dd2-e00e-bb8f0747189b"
      },
      "source": [
        "def prep_batch(batch_data, more_data = False):\n",
        "    \"\"\"\n",
        "        Prepare all the preproccessing that needs to be done on a batch-by-batch basis.\n",
        "    \"\"\"\n",
        "    context_vec, sentence_ends, questionvs, spt, context_words, cqas, answervs, _ = zip(*batch_data)\n",
        "    ends = list(sentence_ends)\n",
        "    maxend = max(map(len, ends))\n",
        "    aends = np.zeros((len(ends), maxend))\n",
        "    for index, i in enumerate(ends):\n",
        "        for indexj, x in enumerate(i):\n",
        "            aends[index, indexj] = x-1\n",
        "    new_ends = np.zeros(aends.shape+(2,))\n",
        "\n",
        "    for index, x in np.ndenumerate(aends):\n",
        "        new_ends[index+(0,)] = index[0]\n",
        "        new_ends[index+(1,)] = x\n",
        "\n",
        "    contexts = list(context_vec)\n",
        "    max_context_length = max([len(x) for x in contexts])\n",
        "    contextsize = list(np.array(contexts[0]).shape)\n",
        "    contextsize[0] = max_context_length\n",
        "    final_contexts = np.zeros([len(contexts)]+contextsize)\n",
        "\n",
        "    contexts = [np.array(x) for x in contexts]\n",
        "    for i, context in enumerate(contexts):\n",
        "        final_contexts[i,0:len(context),:] = context\n",
        "    max_query_length = max(len(x) for x in questionvs)\n",
        "    querysize = list(np.array(questionvs[0]).shape)\n",
        "    querysize[:1] = [len(questionvs),max_query_length]\n",
        "    queries = np.zeros(querysize)\n",
        "    querylengths = np.array(list(zip(range(len(questionvs)),[len(q)-1 for q in questionvs])))\n",
        "    questions = [np.array(q) for q in questionvs]\n",
        "    for i, question in enumerate(questions):\n",
        "        queries[i,0:len(question),:] = question\n",
        "    data = {context_placeholder: final_contexts, input_sentence_endings: new_ends, \n",
        "                            query:queries, input_query_lengths:querylengths, gold_standard: answervs}\n",
        "    return (data, context_words, cqas) if more_data else data\n",
        "\n",
        "# Use TQDM if installed\n",
        "tqdm_installed = False\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "    tqdm_installed = True\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "# Prepare validation set\n",
        "batch = np.random.randint(final_test_data.shape[0], size=batch_size*10)\n",
        "batch_data = final_test_data[batch]\n",
        "\n",
        "validation_set, val_context_words, val_cqas = prep_batch(batch_data, True)\n",
        "\n",
        "# training_iterations_count: The number of data pieces to train on in total\n",
        "# batch_size: The number of data pieces per batch\n",
        "def train(iterations, batch_size):\n",
        "    training_iterations = range(0,iterations,batch_size)\n",
        "    if tqdm_installed:\n",
        "        # Add a progress bar if TQDM is installed\n",
        "        training_iterations = tqdm(training_iterations)\n",
        "\n",
        "    wordz = []\n",
        "    for j in training_iterations:\n",
        "\n",
        "        batch = np.random.randint(final_train_data.shape[0], size=batch_size)\n",
        "        batch_data = final_train_data[batch]\n",
        "\n",
        "        sess.run([opt_op], feed_dict=prep_batch(batch_data))\n",
        "        if (j/batch_size) % display_step == 0:\n",
        "\n",
        "            # Calculate batch accuracy\n",
        "            acc, ccs, tmp_loss, log, con, cor, loc  = sess.run([corrects, cs, total_loss, logit,\n",
        "                                                                context_placeholder,corr, locs], \n",
        "                                                               feed_dict=validation_set)\n",
        "            # Display results\n",
        "            print(\"Iter \" + str(j/batch_size) + \", Minibatch Loss= \",tmp_loss,\n",
        "                  \"Accuracy= \", np.mean(acc))\n",
        "train(30000,batch_size) # Small amount of training for preliminary results\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/235 [00:06<23:36,  6.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 0.0, Minibatch Loss=  0.6734771 Accuracy=  0.1296875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 101/235 [02:31<04:18,  1.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 100.0, Minibatch Loss=  0.67331827 Accuracy=  0.2859375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 201/235 [04:53<01:04,  1.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 200.0, Minibatch Loss=  0.6732771 Accuracy=  0.41328126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [05:40<00:00,  1.38s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-AhtNJlC1WD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "889af26d-6b91-407f-9aa2-15a111c72a7b"
      },
      "source": [
        "ancr = sess.run([corrbool,locs, total_loss, logits, facts_0s, w_1]+attends+\n",
        "                [query, cs, question_module_outputs],feed_dict=validation_set)\n",
        "a = ancr[0]\n",
        "n = ancr[1]\n",
        "cr = ancr[2]\n",
        "attenders = np.array(ancr[6:-3]) \n",
        "faq = np.sum(ancr[4], axis=(-1,-2)) # Number of facts in each context\n",
        "\n",
        "limit = 5\n",
        "for question in range(min(limit, batch_size)):\n",
        "    plt.yticks(range(passes,0,-1))\n",
        "    plt.ylabel(\"Episode\")\n",
        "    plt.xlabel(\"Question \"+str(question+1))\n",
        "    pltdata = attenders[:,question,:int(faq[question]),0] \n",
        "    # Display only information about facts that actually exist, all others are 0\n",
        "    pltdata = (pltdata - pltdata.mean()) / ((pltdata.max() - pltdata.min() + 0.001)) * 256\n",
        "    plt.pcolor(pltdata, cmap=plt.cm.BuGn, alpha=0.7)\n",
        "    plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYwx+SWqMwS9Jjfl/OeO2V5ZNFRMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhTDwJakQBr4kFcLAl6RCGPiSVIj/BxnATZIHyT5MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWZYkLLiEMGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "08419d8d-ba91-425d-8a68-62d603b8294a"
      },
      "source": [
        "# Locations of responses within contexts\n",
        "indices = np.argmax(n,axis=1)\n",
        "\n",
        "# Locations of actual answers within contexts \n",
        "indicesc = np.argmax(a,axis=1)\n",
        "\n",
        "for i,e,cw, cqa in list(zip(indices, indicesc, val_context_words, val_cqas))[:limit]:\n",
        "    ccc = \" \".join(cw)\n",
        "    print(\"TEXT: \",ccc)\n",
        "    print (\"QUESTION: \", \" \".join(cqa[3]))\n",
        "    print (\"RESPONSE: \", cw[i], [\"Correct\", \"Incorrect\"][i!=e])\n",
        "    print(\"EXPECTED: \", cw[e])\n",
        "    print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEXT:  bill travelled to the office . jeff took the apple there . jeff put down the apple . bill moved to the bedroom . jeff picked up the milk there . bill moved to the garden . bill journeyed to the bedroom . jeff went back to the office . jeff handed the milk to mary . bill went back to the bathroom . fred went to the office . bill travelled to the kitchen .\n",
            "QUESTION:  what did jeff give to mary ?\n",
            "RESPONSE:  apple Incorrect\n",
            "EXPECTED:  milk\n",
            "\n",
            "TEXT:  jeff travelled to the bathroom . bill journeyed to the bedroom . jeff journeyed to the hallway . bill took the milk there . bill discarded the milk . mary moved to the bedroom . jeff went back to the bedroom . fred got the football there . bill grabbed the milk there . bill passed the milk to mary . mary gave the milk to bill . bill discarded the milk there . bill went to the kitchen . bill got the apple there . fred dropped the football . mary went to the garden . fred travelled to the kitchen . fred went back to the bedroom . fred got the milk there . fred handed the milk to jeff . fred moved to the bathroom . bill moved to the bedroom .\n",
            "QUESTION:  who received the milk ?\n",
            "RESPONSE:  fred Incorrect\n",
            "EXPECTED:  jeff\n",
            "\n",
            "TEXT:  mary travelled to the office . jeff went to the garden . jeff went back to the hallway . mary grabbed the milk there . mary picked up the football there . mary picked up the apple there . jeff travelled to the kitchen . bill moved to the garden . bill went back to the kitchen . fred moved to the garden . mary dropped the football . mary went back to the kitchen . jeff journeyed to the office . bill journeyed to the office . bill journeyed to the garden . fred moved to the bedroom . mary left the milk . bill went to the office . mary went to the bedroom . mary journeyed to the office . jeff grabbed the football there . mary went to the bathroom . mary went to the garden . jeff handed the football to bill . mary travelled to the kitchen . bill gave the football to jeff . mary dropped the apple . jeff gave the football to bill . bill passed the football to jeff . jeff travelled to the bathroom . bill went back to the garden . jeff dropped the football .\n",
            "QUESTION:  who gave the football ?\n",
            "RESPONSE:  mary Incorrect\n",
            "EXPECTED:  bill\n",
            "\n",
            "TEXT:  mary went to the bedroom . jeff went to the office . mary travelled to the kitchen . bill moved to the office . mary moved to the office . fred went to the bathroom . fred journeyed to the office . bill went to the bathroom . jeff travelled to the bathroom . fred went to the garden . bill went back to the hallway . fred got the football there . bill went to the bedroom . jeff went back to the office . fred got the milk there . mary journeyed to the garden . bill travelled to the office . fred travelled to the hallway . fred went back to the bedroom . jeff went back to the hallway . bill journeyed to the bedroom . bill went back to the hallway . fred left the football . fred went back to the kitchen . mary journeyed to the hallway . jeff journeyed to the bedroom . fred went to the hallway . bill journeyed to the bathroom . bill journeyed to the garden . fred gave the milk to mary . mary discarded the milk . jeff got the football there . mary got the milk there . mary passed the milk to fred . fred handed the milk to mary . jeff put down the football .\n",
            "QUESTION:  what did fred give to mary ?\n",
            "RESPONSE:  football Incorrect\n",
            "EXPECTED:  milk\n",
            "\n",
            "TEXT:  fred travelled to the bedroom . jeff grabbed the milk there . jeff dropped the milk . fred journeyed to the bathroom . fred grabbed the football there . bill journeyed to the kitchen . mary moved to the bathroom . jeff went to the bedroom . fred put down the football there . fred went to the kitchen . bill journeyed to the garden . bill journeyed to the bathroom . bill took the football there . fred went back to the bathroom . bill handed the football to mary . mary passed the football to fred . fred handed the football to mary . mary went to the office . mary took the milk there . mary went to the bedroom . mary gave the football to jeff . mary travelled to the office .\n",
            "QUESTION:  what did mary give to jeff ?\n",
            "RESPONSE:  milk Incorrect\n",
            "EXPECTED:  football\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kbg8LwLET54",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "317ca4c2-9854-42a1-99c0-cd8ba9a32380"
      },
      "source": [
        "train(training_iterations_count, batch_size)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/3125 [00:03<2:53:15,  3.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 0.0, Minibatch Loss=  0.6732762 Accuracy=  0.40703124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 101/3125 [02:25<1:29:51,  1.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 100.0, Minibatch Loss=  0.67325836 Accuracy=  0.47734374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|▋         | 201/3125 [04:48<1:37:14,  2.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 200.0, Minibatch Loss=  0.6732447 Accuracy=  0.53203124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|▉         | 301/3125 [07:03<1:27:16,  1.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 300.0, Minibatch Loss=  0.67323184 Accuracy=  0.571875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 401/3125 [09:21<1:23:00,  1.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 400.0, Minibatch Loss=  0.6732247 Accuracy=  0.6265625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 501/3125 [11:40<1:19:11,  1.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 500.0, Minibatch Loss=  0.67321146 Accuracy=  0.69609374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 601/3125 [14:01<1:22:33,  1.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 600.0, Minibatch Loss=  0.6732086 Accuracy=  0.7210938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 701/3125 [16:20<1:07:50,  1.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 700.0, Minibatch Loss=  0.673192 Accuracy=  0.7914063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 801/3125 [18:44<1:08:26,  1.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 800.0, Minibatch Loss=  0.67317986 Accuracy=  0.8148438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 901/3125 [21:09<1:09:24,  1.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 900.0, Minibatch Loss=  0.67317665 Accuracy=  0.8328125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 1001/3125 [23:31<1:09:54,  1.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1000.0, Minibatch Loss=  0.67317784 Accuracy=  0.82109374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 1101/3125 [25:52<1:05:13,  1.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1100.0, Minibatch Loss=  0.6731654 Accuracy=  0.8773438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 1201/3125 [28:17<1:00:24,  1.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1200.0, Minibatch Loss=  0.6731651 Accuracy=  0.8609375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1301/3125 [30:34<59:13,  1.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1300.0, Minibatch Loss=  0.673158 Accuracy=  0.896875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 1401/3125 [32:58<47:56,  1.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1400.0, Minibatch Loss=  0.67315656 Accuracy=  0.90234375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 1501/3125 [35:22<50:03,  1.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1500.0, Minibatch Loss=  0.6731571 Accuracy=  0.8960937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1601/3125 [37:42<48:03,  1.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1600.0, Minibatch Loss=  0.6731522 Accuracy=  0.9109375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 1701/3125 [40:05<47:34,  2.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1700.0, Minibatch Loss=  0.67315185 Accuracy=  0.91328126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 1801/3125 [42:30<42:46,  1.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1800.0, Minibatch Loss=  0.673148 Accuracy=  0.93359375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 61%|██████    | 1901/3125 [44:50<39:00,  1.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 1900.0, Minibatch Loss=  0.6731504 Accuracy=  0.92109376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 2001/3125 [47:15<35:26,  1.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2000.0, Minibatch Loss=  0.67315024 Accuracy=  0.91875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2101/3125 [49:33<33:12,  1.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2100.0, Minibatch Loss=  0.67314965 Accuracy=  0.91875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 2201/3125 [51:52<29:57,  1.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2200.0, Minibatch Loss=  0.6731456 Accuracy=  0.928125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 74%|███████▎  | 2301/3125 [54:13<26:30,  1.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2300.0, Minibatch Loss=  0.6731459 Accuracy=  0.93359375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 2401/3125 [56:31<20:18,  1.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2400.0, Minibatch Loss=  0.67316353 Accuracy=  0.884375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 2501/3125 [58:47<19:46,  1.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2500.0, Minibatch Loss=  0.67315453 Accuracy=  0.90703124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 2601/3125 [1:01:12<15:15,  1.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2600.0, Minibatch Loss=  0.6731433 Accuracy=  0.94375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 2701/3125 [1:03:30<11:55,  1.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2700.0, Minibatch Loss=  0.67314225 Accuracy=  0.9453125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 2801/3125 [1:05:48<10:21,  1.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2800.0, Minibatch Loss=  0.67314535 Accuracy=  0.9320313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 2901/3125 [1:08:13<06:46,  1.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 2900.0, Minibatch Loss=  0.6731436 Accuracy=  0.9390625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 3001/3125 [1:10:34<04:01,  1.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 3000.0, Minibatch Loss=  0.6731453 Accuracy=  0.93671876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 3101/3125 [1:12:57<00:40,  1.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 3100.0, Minibatch Loss=  0.6731419 Accuracy=  0.95703125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3125/3125 [1:13:30<00:00,  1.24s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxQALIjMEm0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ce13e06-153e-4768-a9b8-88895ea667c0"
      },
      "source": [
        "print(np.mean(sess.run([corrects], feed_dict= prep_batch(final_test_data))[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLKn4nNkXlO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_5tvN17Xr9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}